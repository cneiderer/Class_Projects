{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import add_dummy_feature\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "import scikitplot as skplt\n",
    "import mord\n",
    "\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('winequality-red.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Relabel\n",
    "# df.quality = pd.cut(df.quality, bins=3, labels=[1, 2, 3]).astype('int')\n",
    "df.quality = df.quality.map(lambda x: x-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        2  \n",
       "1      9.8        2  \n",
       "2      9.8        2  \n",
       "3      9.8        3  \n",
       "4      9.4        2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_subset = df.copy()\n",
    "df_subset['quality2'] = pd.cut(df.quality, bins=3, labels=[1, 2, 3]).astype('int') #['good', 'medium', 'bad'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
       "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
       "       'pH', 'sulphates', 'alcohol', 'quality'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split \n",
    "# y = resampled_df.quality\n",
    "# X = resampled_df.drop(columns='quality')\n",
    "\n",
    "# y = df_subset.quality2\n",
    "# X = df_subset.drop(columns=['quality', 'quality2'])\n",
    "\n",
    "y = df.quality\n",
    "X = df[['fixed acidity', 'volatile acidity', 'free sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol']]\n",
    "\n",
    "# y = df.quality\n",
    "# X = df.drop(columns='quality')\n",
    "\n",
    "# X = df[['volatile acidity', 'citric acid', 'total sulfur dioxide', 'density', 'alcohol']]\n",
    "# X = df[['volatile acidity', 'alcohol']]\n",
    "\n",
    "# # Make sure intercept exists\n",
    "# if ~any(X.columns == 'Intercept'):\n",
    "#     X.insert(0, 'Intercept', 1)\n",
    "# else: \n",
    "#     X.Intercept = 1\n",
    "    \n",
    "# Stratified Split\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, stratify=y, test_size=.7, random_state=129)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_confusion_matrix(cm):\n",
    "    \n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    cm = np.around(cm, decimals=2)\n",
    "    cm[np.isnan(cm)] = 0.0\n",
    "    \n",
    "    cm = (cm - np.min(cm)) / (np.max(cm) - np.min(cm))\n",
    "    \n",
    "    return cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discrete_heatmap(cm):\n",
    "    \n",
    "    ### Discrete Confusion Matrix Heatmap\n",
    "    from sklearn.preprocessing import normalize\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    #     # Normalize across predictions\n",
    "    #     norm_Z = normalize(cm, axis=1)\n",
    "    #     # Normalize across predictions and truth [Note: Use this if classes are balanced]\n",
    "    #     norm_Z = (Z - np.min(Z)) / (np.max(Z) - np.min(Z))\n",
    "\n",
    "    #     norm_Z = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    #     norm_Z = np.around(norm_Z, decimals=2)\n",
    "    #     norm_Z[np.isnan(norm_Z)] = 0.0\n",
    "    \n",
    "    Z = normalize_confusion_matrix(cm)\n",
    "\n",
    "    # Generate heatmap\n",
    "    sns.heatmap(Z, cmap='RdYlGn', annot=True, cbar=True)\n",
    "\n",
    "    ## Format axes object\n",
    "    #  Format X-axis label and ticks\n",
    "    ax.set_xlabel('Predicted', fontdict={'size': 12})\n",
    "    ax.xaxis.set_ticks_position('top') \n",
    "    ax.xaxis.set_label_position('top')\n",
    "    # Format Y-axis label\n",
    "    ax.set_ylabel('Truth', fontdict={'size': 12})\n",
    "    # Format Title [Note: double newlines are to create space between Title and the X-axis label that was moved to the top]\n",
    "    ax.set_title('Red Wine Quality Confusion Matrix\\n\\n', fontdict={'size': 14, 'weight': 'bold'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def interpolated_heatmap(cm):\n",
    "    \n",
    "    ### Interpolated Confusion Matrix Heatmap\n",
    "    import numpy as np\n",
    "    from sklearn.preprocessing import normalize\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    #     # Normalize across predictions [Note: Use this if classes are imbalanced]\n",
    "    #     norm_Z = normalize(cm, axis=1)\n",
    "    #     # Normalize across predictions and truth [Note: Use this if classes are balanced]\n",
    "    #     norm_Z = (Z - np.min(Z)) / (np.max(Z) - np.min(Z))\n",
    "\n",
    "    #     norm_Z = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    #     norm_Z = np.around(norm_Z, decimals=2)\n",
    "    #     norm_Z[np.isnan(norm_Z)] = 0.0\n",
    "    \n",
    "    Z = normalize_confusion_matrix(cm)\n",
    "\n",
    "    # Generate X, Y indices of confusion matrix\n",
    "    n_classes = Z.shape[0]\n",
    "    X, Y = np.meshgrid(np.arange(0, n_classes, 1), np.arange(n_classes-1, -1, -1))\n",
    "\n",
    "    # Plot contours\n",
    "    plt.contourf(X, Y, Z, 25, cmap='RdYlGn')#, vmin=0, vmax=1)\n",
    "    ax2 = plt.colorbar();\n",
    "\n",
    "    ## Format X-axis label and ticks\n",
    "    ax.set_xlabel('Predicted', fontdict={'size': 12})\n",
    "    # Move ticks and label to top\n",
    "    ax.xaxis.set_ticks_position('top') \n",
    "    ax.xaxis.set_label_position('top')\n",
    "    # Hide major tick labels\n",
    "    ax.set_xticklabels([], minor=False) \n",
    "    # Create minor ticks in between and label every other one\n",
    "    ax.set_xticks([0.5, 1.5, 2.5, 3.5, 4.5], minor=True)\n",
    "    ax.set_xticklabels(['Low', '', 'Med', '', 'High'], minor=True)\n",
    "\n",
    "    ## Format Y-axis label and ticks\n",
    "    ax.set_ylabel('Truth', fontdict={'size': 12})\n",
    "    # Hide major tick labels\n",
    "    ax.set_yticklabels([], minor=False)\n",
    "    # Create minor ticks in between and label every other one\n",
    "    ax.set_yticks([0.5, 1.5, 2.5, 3.5, 4.5], minor=True)\n",
    "    ax.set_yticklabels(['High', '', 'Med', '', 'Low'], minor=True)\n",
    "\n",
    "    # Format Title [Note: double newlines are to create space between Title and the X-axis label that was moved to the top]\n",
    "    ax.set_title('Red Wine Quality\\n\\n', fontdict={'size': 14, 'weight': 'bold'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        2  \n",
       "1      9.8        2  \n",
       "2      9.8        2  \n",
       "3      9.8        3  \n",
       "4      9.4        2  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.319637</td>\n",
       "      <td>0.527821</td>\n",
       "      <td>0.270976</td>\n",
       "      <td>2.538806</td>\n",
       "      <td>0.087467</td>\n",
       "      <td>15.874922</td>\n",
       "      <td>46.467792</td>\n",
       "      <td>0.996747</td>\n",
       "      <td>3.311113</td>\n",
       "      <td>0.658149</td>\n",
       "      <td>10.422983</td>\n",
       "      <td>2.636023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.741096</td>\n",
       "      <td>0.179060</td>\n",
       "      <td>0.194801</td>\n",
       "      <td>1.409928</td>\n",
       "      <td>0.047065</td>\n",
       "      <td>10.460157</td>\n",
       "      <td>32.895324</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.154386</td>\n",
       "      <td>0.169507</td>\n",
       "      <td>1.065668</td>\n",
       "      <td>0.807569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.990070</td>\n",
       "      <td>2.740000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.100000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.995600</td>\n",
       "      <td>3.210000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.996750</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.200000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.997835</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.900000</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>1.003690</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count    1599.000000       1599.000000  1599.000000     1599.000000   \n",
       "mean        8.319637          0.527821     0.270976        2.538806   \n",
       "std         1.741096          0.179060     0.194801        1.409928   \n",
       "min         4.600000          0.120000     0.000000        0.900000   \n",
       "25%         7.100000          0.390000     0.090000        1.900000   \n",
       "50%         7.900000          0.520000     0.260000        2.200000   \n",
       "75%         9.200000          0.640000     0.420000        2.600000   \n",
       "max        15.900000          1.580000     1.000000       15.500000   \n",
       "\n",
       "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
       "count  1599.000000          1599.000000           1599.000000  1599.000000   \n",
       "mean      0.087467            15.874922             46.467792     0.996747   \n",
       "std       0.047065            10.460157             32.895324     0.001887   \n",
       "min       0.012000             1.000000              6.000000     0.990070   \n",
       "25%       0.070000             7.000000             22.000000     0.995600   \n",
       "50%       0.079000            14.000000             38.000000     0.996750   \n",
       "75%       0.090000            21.000000             62.000000     0.997835   \n",
       "max       0.611000            72.000000            289.000000     1.003690   \n",
       "\n",
       "                pH    sulphates      alcohol      quality  \n",
       "count  1599.000000  1599.000000  1599.000000  1599.000000  \n",
       "mean      3.311113     0.658149    10.422983     2.636023  \n",
       "std       0.154386     0.169507     1.065668     0.807569  \n",
       "min       2.740000     0.330000     8.400000     0.000000  \n",
       "25%       3.210000     0.550000     9.500000     2.000000  \n",
       "50%       3.310000     0.620000    10.200000     3.000000  \n",
       "75%       3.400000     0.730000    11.100000     3.000000  \n",
       "max       4.010000     2.000000    14.900000     5.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def error_distance_cost(y_true, y_pred):\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm = normalize_confusion_matrix(cm)\n",
    "    \n",
    "    cost = np.zeros_like(cm)\n",
    "    rows, cols = cm.shape\n",
    "    for ridx in range(rows):\n",
    "        for cidx in range(cols):\n",
    "            cost[ridx, cidx] = np.abs(ridx-cidx) * cm[ridx, cidx]\n",
    "\n",
    "    return np.around(1/np.sum(cost), decimals=5)\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    \n",
    "    return f1_score(y_true, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=10000,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=129,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'C': array([  1.00000e-09,   1.00000e-08,   1.00000e-07,   1.00000e-06,\n",
       "         1.00000e-05,   1.00000e-04,   1.00000e-03,   1.00000e-02,\n",
       "         1.00000e-01,   1.00000e+00,   1.00000e+01,   1.00000e+02,\n",
       "         1.00000e+03,   1.00000e+04,   1.00000e+05,   1.00000e+06,\n",
       "         1.00000e+07,   1.00000e+08,   1.00000e+09]), 'penalty': ['l1', 'l2'], 'multi_class': ['ovr'], 'solver': ['liblinear', 'saga']}],\n",
       "       pre_dispatch='2*n_jobs', refit='ErrorDistance',\n",
       "       return_train_score=True,\n",
       "       scoring={'Accuracy': 'accuracy', 'ErrorDistance': make_scorer(error_distance_cost)},\n",
       "       verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr0 = LogisticRegression(class_weight='balanced', \n",
    "                         random_state=129,\n",
    "                         max_iter=10000)\n",
    "scoring = {'Accuracy': 'accuracy',\n",
    "#            'F1': make_scorer(f1), \n",
    "           'ErrorDistance': make_scorer(error_distance_cost)}\n",
    "param_grid = [{'C': np.logspace(-9, 9, 19), \n",
    "               'penalty': ['l1', 'l2'],\n",
    "               'multi_class': ['ovr'],\n",
    "               'solver': ['liblinear', 'saga']}]\n",
    "\n",
    "searchcv = GridSearchCV(lr0, param_grid, scoring=scoring, cv=3, \n",
    "                        return_train_score=True, refit='ErrorDistance')\n",
    "\n",
    "searchcv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.209823674322\n",
      "4.7659064366\n"
     ]
    }
   ],
   "source": [
    "print(searchcv.best_score_)\n",
    "print(1 / searchcv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=10000,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=129,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchcv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([  1.79449717e-03,   4.16572889e-03,   1.66885058e-03,\n",
       "          9.21861331e-03,   1.20949745e-03,   3.46509616e-03,\n",
       "          1.62450473e-03,   6.72086080e-03,   1.13407771e-03,\n",
       "          3.52136294e-03,   1.67576472e-03,   7.07451502e-03,\n",
       "          1.20854378e-03,   3.32776705e-03,   1.71438853e-03,\n",
       "          1.10461712e-02,   1.26886368e-03,   3.64327431e-03,\n",
       "          2.04435984e-03,   6.39929771e-02,   1.27919515e-03,\n",
       "          3.58168284e-03,   2.56045659e-03,   9.59526698e-01,\n",
       "          1.67767207e-03,   8.24069977e-03,   3.05612882e-03,\n",
       "          1.46377500e+00,   3.51587931e-03,   1.76154558e+00,\n",
       "          3.05668513e-03,   2.45310966e+00,   9.89429156e-03,\n",
       "          2.84012071e+00,   4.57024574e-03,   1.98485843e+00,\n",
       "          8.62792333e-02,   1.75921623e+00,   5.35416603e-03,\n",
       "          1.98071210e+00,   3.98034016e-01,   2.48949742e+00,\n",
       "          6.60061836e-03,   1.97581196e+00,   1.60429136e+00,\n",
       "          2.79287799e+00,   7.83069928e-03,   2.29438527e+00,\n",
       "          7.64873981e+00,   3.33553386e+00,   9.39130783e-03,\n",
       "          2.38894971e+00,   1.56745962e+01,   2.74877866e+00,\n",
       "          9.53872999e-03,   2.23041876e+00,   1.69426714e+01,\n",
       "          2.80405092e+00,   1.06294155e-02,   2.31184824e+00,\n",
       "          1.94636064e+01,   3.29549853e+00,   1.21609370e-02,\n",
       "          2.30830542e+00,   1.73718793e+01,   3.13834278e+00,\n",
       "          1.34391785e-02,   2.41942970e+00,   1.71614149e+01,\n",
       "          2.80322019e+00,   1.23519897e-02,   2.26253263e+00,\n",
       "          1.84846814e+01,   3.47558705e+00,   1.54332320e-02,\n",
       "          2.45108406e+00]),\n",
       " 'mean_score_time': array([ 0.00552336,  0.00114957,  0.00125202,  0.00144704,  0.00101336,\n",
       "         0.00100946,  0.00100875,  0.00103577,  0.00100954,  0.00100104,\n",
       "         0.00101709,  0.00101527,  0.00100001,  0.00098904,  0.00099524,\n",
       "         0.00105778,  0.00102441,  0.00107956,  0.00101972,  0.00123032,\n",
       "         0.0010798 ,  0.00100819,  0.00109887,  0.00126839,  0.00103553,\n",
       "         0.00153637,  0.00137067,  0.00122142,  0.00101185,  0.00122046,\n",
       "         0.00102258,  0.00125392,  0.00101582,  0.00153645,  0.00127435,\n",
       "         0.00120854,  0.00120997,  0.00125504,  0.00101233,  0.00124041,\n",
       "         0.00121586,  0.0012699 ,  0.00110682,  0.00125559,  0.00122039,\n",
       "         0.0012327 ,  0.0010066 ,  0.00133236,  0.00123215,  0.00138728,\n",
       "         0.00109641,  0.00133689,  0.00131035,  0.00120727,  0.00100589,\n",
       "         0.00132656,  0.00135684,  0.00124725,  0.00101264,  0.001273  ,\n",
       "         0.00140452,  0.00124502,  0.0010581 ,  0.00131305,  0.00125949,\n",
       "         0.00129509,  0.00108528,  0.00126306,  0.00128269,  0.0013152 ,\n",
       "         0.00111985,  0.00149481,  0.00132314,  0.00139149,  0.00139062,\n",
       "         0.00126974]),\n",
       " 'mean_test_Accuracy': array([ 0.00626305,  0.13569937,  0.42588727,  0.15240084,  0.00626305,\n",
       "         0.13569937,  0.42588727,  0.15240084,  0.00626305,  0.13569937,\n",
       "         0.42588727,  0.15240084,  0.00626305,  0.13569937,  0.42588727,\n",
       "         0.1565762 ,  0.00626305,  0.13569937,  0.43006263,  0.14822547,\n",
       "         0.00626305,  0.17536534,  0.46137787,  0.17536534,  0.42588727,\n",
       "         0.15448852,  0.43841336,  0.09185804,  0.43006263,  0.1565762 ,\n",
       "         0.39665971,  0.14613779,  0.3736952 ,  0.34864301,  0.44258873,\n",
       "         0.11064718,  0.46555324,  0.3736952 ,  0.47390397,  0.29227557,\n",
       "         0.48016701,  0.30271399,  0.47599165,  0.36743215,  0.47807933,\n",
       "         0.35490605,  0.47807933,  0.38204593,  0.48016701,  0.3256785 ,\n",
       "         0.47599165,  0.38204593,  0.48016701,  0.30688935,  0.48016701,\n",
       "         0.38204593,  0.4822547 ,  0.30480167,  0.48434238,  0.38204593,\n",
       "         0.48016701,  0.38830898,  0.4822547 ,  0.38830898,  0.48016701,\n",
       "         0.35073069,  0.49060543,  0.39665971,  0.48016701,  0.30688935,\n",
       "         0.49060543,  0.38204593,  0.48016701,  0.3611691 ,  0.49060543,\n",
       "         0.38204593]),\n",
       " 'mean_test_ErrorDistance': array([ 0.06667   ,  0.08132871,  0.11111   ,  0.08120666,  0.06667   ,\n",
       "         0.08132871,  0.11111   ,  0.08120666,  0.06667   ,  0.08132871,\n",
       "         0.11111   ,  0.08116708,  0.06667   ,  0.08132871,  0.11111   ,\n",
       "         0.08068879,  0.06667   ,  0.08132871,  0.11067286,  0.08218511,\n",
       "         0.06667   ,  0.08942557,  0.10728253,  0.08984762,  0.11111   ,\n",
       "         0.09757305,  0.10710653,  0.0740376 ,  0.10371559,  0.09043768,\n",
       "         0.10972027,  0.08432493,  0.14195898,  0.1673899 ,  0.1588542 ,\n",
       "         0.08457843,  0.18984025,  0.19810397,  0.18459537,  0.14893691,\n",
       "         0.20236324,  0.16353779,  0.20982367,  0.19139681,  0.20381382,\n",
       "         0.19171409,  0.20934875,  0.19938791,  0.20318263,  0.17741106,\n",
       "         0.19463144,  0.19947367,  0.20318263,  0.16650528,  0.19409386,\n",
       "         0.19947367,  0.2032552 ,  0.16593056,  0.19388829,  0.19930225,\n",
       "         0.20318263,  0.20098904,  0.19742008,  0.20125173,  0.20318263,\n",
       "         0.19062507,  0.20171236,  0.20753712,  0.20318263,  0.16669019,\n",
       "         0.20136497,  0.19930225,  0.20318263,  0.19681971,  0.20119127,\n",
       "         0.19930225]),\n",
       " 'mean_train_Accuracy': array([ 0.00626314,  0.13710426,  0.42589375,  0.14541164,  0.00626314,\n",
       "         0.13710426,  0.42589375,  0.14541164,  0.00626314,  0.13710426,\n",
       "         0.42589375,  0.14229637,  0.00626314,  0.13710426,  0.42589375,\n",
       "         0.15164217,  0.00626314,  0.13710426,  0.43214059,  0.16875275,\n",
       "         0.00626314,  0.17681168,  0.4613533 ,  0.20006718,  0.42589375,\n",
       "         0.1548944 ,  0.43430535,  0.09974062,  0.4436806 ,  0.17918801,\n",
       "         0.4197122 ,  0.14162042,  0.38935319,  0.36640083,  0.46669211,\n",
       "         0.12885549,  0.50726533,  0.40924664,  0.51047527,  0.33790848,\n",
       "         0.53965226,  0.34426729,  0.5385746 ,  0.41752084,  0.54792361,\n",
       "         0.39980325,  0.54271849,  0.43321473,  0.55316793,  0.37361739,\n",
       "         0.54583697,  0.43844273,  0.55421937,  0.34426406,  0.54481486,\n",
       "         0.43844273,  0.55525779,  0.33796818,  0.54585979,  0.43739452,\n",
       "         0.55525779,  0.43742731,  0.55004938,  0.44473204,  0.55525779,\n",
       "         0.39457195,  0.55424219,  0.44997313,  0.55525779,  0.34740214,\n",
       "         0.55424219,  0.43844273,  0.55525779,  0.40819879,  0.55424219,\n",
       "         0.43844273]),\n",
       " 'mean_train_ErrorDistance': array([ 0.06667   ,  0.08148333,  0.11111   ,  0.08136   ,  0.06667   ,\n",
       "         0.08148333,  0.11111   ,  0.08136   ,  0.06667   ,  0.08148333,\n",
       "         0.11111   ,  0.08128   ,  0.06667   ,  0.08148333,  0.11111   ,\n",
       "         0.08038667,  0.06667   ,  0.08148333,  0.11139667,  0.05781333,\n",
       "         0.06667   ,  0.08956333,  0.09231   ,  0.08362667,  0.11111   ,\n",
       "         0.09764333,  0.08421   ,  0.08294333,  0.08955667,  0.10072333,\n",
       "         0.09866333,  0.08022   ,  0.14096667,  0.17179333,  0.17174   ,\n",
       "         0.09170333,  0.23829667,  0.22152667,  0.22786333,  0.16969   ,\n",
       "         0.32441667,  0.23331667,  0.28901333,  0.24290667,  0.33763333,\n",
       "         0.28043   ,  0.32417   ,  0.23867667,  0.34451667,  0.25268333,\n",
       "         0.33542333,  0.20657   ,  0.34627333,  0.23032   ,  0.33682   ,\n",
       "         0.20657   ,  0.34606667,  0.22746   ,  0.34101667,  0.20632667,\n",
       "         0.34606667,  0.2623    ,  0.35799333,  0.2082    ,  0.34606667,\n",
       "         0.27709333,  0.39834667,  0.19977667,  0.34606667,  0.23111   ,\n",
       "         0.39834667,  0.20657   ,  0.34606667,  0.26596667,  0.39834667,\n",
       "         0.20657   ]),\n",
       " 'param_C': masked_array(data = [1.0000000000000001e-09 1.0000000000000001e-09 1.0000000000000001e-09\n",
       "  1.0000000000000001e-09 1e-08 1e-08 1e-08 1e-08 9.9999999999999995e-08\n",
       "  9.9999999999999995e-08 9.9999999999999995e-08 9.9999999999999995e-08\n",
       "  9.9999999999999995e-07 9.9999999999999995e-07 9.9999999999999995e-07\n",
       "  9.9999999999999995e-07 1.0000000000000001e-05 1.0000000000000001e-05\n",
       "  1.0000000000000001e-05 1.0000000000000001e-05 0.0001 0.0001 0.0001 0.0001\n",
       "  0.001 0.001 0.001 0.001 0.01 0.01 0.01 0.01 0.10000000000000001\n",
       "  0.10000000000000001 0.10000000000000001 0.10000000000000001 1.0 1.0 1.0\n",
       "  1.0 10.0 10.0 10.0 10.0 100.0 100.0 100.0 100.0 1000.0 1000.0 1000.0\n",
       "  1000.0 10000.0 10000.0 10000.0 10000.0 100000.0 100000.0 100000.0 100000.0\n",
       "  1000000.0 1000000.0 1000000.0 1000000.0 10000000.0 10000000.0 10000000.0\n",
       "  10000000.0 100000000.0 100000000.0 100000000.0 100000000.0 1000000000.0\n",
       "  1000000000.0 1000000000.0 1000000000.0],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_multi_class': masked_array(data = ['ovr' 'ovr' 'ovr' 'ovr' 'ovr' 'ovr' 'ovr' 'ovr' 'ovr' 'ovr' 'ovr' 'ovr'\n",
       "  'ovr' 'ovr' 'ovr' 'ovr' 'ovr' 'ovr' 'ovr' 'ovr' 'ovr' 'ovr' 'ovr' 'ovr'\n",
       "  'ovr' 'ovr' 'ovr' 'ovr' 'ovr' 'ovr' 'ovr' 'ovr' 'ovr' 'ovr' 'ovr' 'ovr'\n",
       "  'ovr' 'ovr' 'ovr' 'ovr' 'ovr' 'ovr' 'ovr' 'ovr' 'ovr' 'ovr' 'ovr' 'ovr'\n",
       "  'ovr' 'ovr' 'ovr' 'ovr' 'ovr' 'ovr' 'ovr' 'ovr' 'ovr' 'ovr' 'ovr' 'ovr'\n",
       "  'ovr' 'ovr' 'ovr' 'ovr' 'ovr' 'ovr' 'ovr' 'ovr' 'ovr' 'ovr' 'ovr' 'ovr'\n",
       "  'ovr' 'ovr' 'ovr' 'ovr'],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_penalty': masked_array(data = ['l1' 'l1' 'l2' 'l2' 'l1' 'l1' 'l2' 'l2' 'l1' 'l1' 'l2' 'l2' 'l1' 'l1' 'l2'\n",
       "  'l2' 'l1' 'l1' 'l2' 'l2' 'l1' 'l1' 'l2' 'l2' 'l1' 'l1' 'l2' 'l2' 'l1' 'l1'\n",
       "  'l2' 'l2' 'l1' 'l1' 'l2' 'l2' 'l1' 'l1' 'l2' 'l2' 'l1' 'l1' 'l2' 'l2' 'l1'\n",
       "  'l1' 'l2' 'l2' 'l1' 'l1' 'l2' 'l2' 'l1' 'l1' 'l2' 'l2' 'l1' 'l1' 'l2' 'l2'\n",
       "  'l1' 'l1' 'l2' 'l2' 'l1' 'l1' 'l2' 'l2' 'l1' 'l1' 'l2' 'l2' 'l1' 'l1' 'l2'\n",
       "  'l2'],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_solver': masked_array(data = ['liblinear' 'saga' 'liblinear' 'saga' 'liblinear' 'saga' 'liblinear'\n",
       "  'saga' 'liblinear' 'saga' 'liblinear' 'saga' 'liblinear' 'saga'\n",
       "  'liblinear' 'saga' 'liblinear' 'saga' 'liblinear' 'saga' 'liblinear'\n",
       "  'saga' 'liblinear' 'saga' 'liblinear' 'saga' 'liblinear' 'saga'\n",
       "  'liblinear' 'saga' 'liblinear' 'saga' 'liblinear' 'saga' 'liblinear'\n",
       "  'saga' 'liblinear' 'saga' 'liblinear' 'saga' 'liblinear' 'saga'\n",
       "  'liblinear' 'saga' 'liblinear' 'saga' 'liblinear' 'saga' 'liblinear'\n",
       "  'saga' 'liblinear' 'saga' 'liblinear' 'saga' 'liblinear' 'saga'\n",
       "  'liblinear' 'saga' 'liblinear' 'saga' 'liblinear' 'saga' 'liblinear'\n",
       "  'saga' 'liblinear' 'saga' 'liblinear' 'saga' 'liblinear' 'saga'\n",
       "  'liblinear' 'saga' 'liblinear' 'saga' 'liblinear' 'saga'],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False],\n",
       "        fill_value = ?),\n",
       " 'params': [{'C': 1.0000000000000001e-09,\n",
       "   'multi_class': 'ovr',\n",
       "   'penalty': 'l1',\n",
       "   'solver': 'liblinear'},\n",
       "  {'C': 1.0000000000000001e-09,\n",
       "   'multi_class': 'ovr',\n",
       "   'penalty': 'l1',\n",
       "   'solver': 'saga'},\n",
       "  {'C': 1.0000000000000001e-09,\n",
       "   'multi_class': 'ovr',\n",
       "   'penalty': 'l2',\n",
       "   'solver': 'liblinear'},\n",
       "  {'C': 1.0000000000000001e-09,\n",
       "   'multi_class': 'ovr',\n",
       "   'penalty': 'l2',\n",
       "   'solver': 'saga'},\n",
       "  {'C': 1e-08, 'multi_class': 'ovr', 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 1e-08, 'multi_class': 'ovr', 'penalty': 'l1', 'solver': 'saga'},\n",
       "  {'C': 1e-08, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'liblinear'},\n",
       "  {'C': 1e-08, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'saga'},\n",
       "  {'C': 9.9999999999999995e-08,\n",
       "   'multi_class': 'ovr',\n",
       "   'penalty': 'l1',\n",
       "   'solver': 'liblinear'},\n",
       "  {'C': 9.9999999999999995e-08,\n",
       "   'multi_class': 'ovr',\n",
       "   'penalty': 'l1',\n",
       "   'solver': 'saga'},\n",
       "  {'C': 9.9999999999999995e-08,\n",
       "   'multi_class': 'ovr',\n",
       "   'penalty': 'l2',\n",
       "   'solver': 'liblinear'},\n",
       "  {'C': 9.9999999999999995e-08,\n",
       "   'multi_class': 'ovr',\n",
       "   'penalty': 'l2',\n",
       "   'solver': 'saga'},\n",
       "  {'C': 9.9999999999999995e-07,\n",
       "   'multi_class': 'ovr',\n",
       "   'penalty': 'l1',\n",
       "   'solver': 'liblinear'},\n",
       "  {'C': 9.9999999999999995e-07,\n",
       "   'multi_class': 'ovr',\n",
       "   'penalty': 'l1',\n",
       "   'solver': 'saga'},\n",
       "  {'C': 9.9999999999999995e-07,\n",
       "   'multi_class': 'ovr',\n",
       "   'penalty': 'l2',\n",
       "   'solver': 'liblinear'},\n",
       "  {'C': 9.9999999999999995e-07,\n",
       "   'multi_class': 'ovr',\n",
       "   'penalty': 'l2',\n",
       "   'solver': 'saga'},\n",
       "  {'C': 1.0000000000000001e-05,\n",
       "   'multi_class': 'ovr',\n",
       "   'penalty': 'l1',\n",
       "   'solver': 'liblinear'},\n",
       "  {'C': 1.0000000000000001e-05,\n",
       "   'multi_class': 'ovr',\n",
       "   'penalty': 'l1',\n",
       "   'solver': 'saga'},\n",
       "  {'C': 1.0000000000000001e-05,\n",
       "   'multi_class': 'ovr',\n",
       "   'penalty': 'l2',\n",
       "   'solver': 'liblinear'},\n",
       "  {'C': 1.0000000000000001e-05,\n",
       "   'multi_class': 'ovr',\n",
       "   'penalty': 'l2',\n",
       "   'solver': 'saga'},\n",
       "  {'C': 0.0001, 'multi_class': 'ovr', 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 0.0001, 'multi_class': 'ovr', 'penalty': 'l1', 'solver': 'saga'},\n",
       "  {'C': 0.0001, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'liblinear'},\n",
       "  {'C': 0.0001, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'saga'},\n",
       "  {'C': 0.001, 'multi_class': 'ovr', 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 0.001, 'multi_class': 'ovr', 'penalty': 'l1', 'solver': 'saga'},\n",
       "  {'C': 0.001, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'liblinear'},\n",
       "  {'C': 0.001, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'saga'},\n",
       "  {'C': 0.01, 'multi_class': 'ovr', 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 0.01, 'multi_class': 'ovr', 'penalty': 'l1', 'solver': 'saga'},\n",
       "  {'C': 0.01, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'liblinear'},\n",
       "  {'C': 0.01, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'saga'},\n",
       "  {'C': 0.10000000000000001,\n",
       "   'multi_class': 'ovr',\n",
       "   'penalty': 'l1',\n",
       "   'solver': 'liblinear'},\n",
       "  {'C': 0.10000000000000001,\n",
       "   'multi_class': 'ovr',\n",
       "   'penalty': 'l1',\n",
       "   'solver': 'saga'},\n",
       "  {'C': 0.10000000000000001,\n",
       "   'multi_class': 'ovr',\n",
       "   'penalty': 'l2',\n",
       "   'solver': 'liblinear'},\n",
       "  {'C': 0.10000000000000001,\n",
       "   'multi_class': 'ovr',\n",
       "   'penalty': 'l2',\n",
       "   'solver': 'saga'},\n",
       "  {'C': 1.0, 'multi_class': 'ovr', 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 1.0, 'multi_class': 'ovr', 'penalty': 'l1', 'solver': 'saga'},\n",
       "  {'C': 1.0, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'liblinear'},\n",
       "  {'C': 1.0, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'saga'},\n",
       "  {'C': 10.0, 'multi_class': 'ovr', 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 10.0, 'multi_class': 'ovr', 'penalty': 'l1', 'solver': 'saga'},\n",
       "  {'C': 10.0, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'liblinear'},\n",
       "  {'C': 10.0, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'saga'},\n",
       "  {'C': 100.0, 'multi_class': 'ovr', 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 100.0, 'multi_class': 'ovr', 'penalty': 'l1', 'solver': 'saga'},\n",
       "  {'C': 100.0, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'liblinear'},\n",
       "  {'C': 100.0, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'saga'},\n",
       "  {'C': 1000.0, 'multi_class': 'ovr', 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 1000.0, 'multi_class': 'ovr', 'penalty': 'l1', 'solver': 'saga'},\n",
       "  {'C': 1000.0, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'liblinear'},\n",
       "  {'C': 1000.0, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'saga'},\n",
       "  {'C': 10000.0, 'multi_class': 'ovr', 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 10000.0, 'multi_class': 'ovr', 'penalty': 'l1', 'solver': 'saga'},\n",
       "  {'C': 10000.0, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'liblinear'},\n",
       "  {'C': 10000.0, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'saga'},\n",
       "  {'C': 100000.0,\n",
       "   'multi_class': 'ovr',\n",
       "   'penalty': 'l1',\n",
       "   'solver': 'liblinear'},\n",
       "  {'C': 100000.0, 'multi_class': 'ovr', 'penalty': 'l1', 'solver': 'saga'},\n",
       "  {'C': 100000.0,\n",
       "   'multi_class': 'ovr',\n",
       "   'penalty': 'l2',\n",
       "   'solver': 'liblinear'},\n",
       "  {'C': 100000.0, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'saga'},\n",
       "  {'C': 1000000.0,\n",
       "   'multi_class': 'ovr',\n",
       "   'penalty': 'l1',\n",
       "   'solver': 'liblinear'},\n",
       "  {'C': 1000000.0, 'multi_class': 'ovr', 'penalty': 'l1', 'solver': 'saga'},\n",
       "  {'C': 1000000.0,\n",
       "   'multi_class': 'ovr',\n",
       "   'penalty': 'l2',\n",
       "   'solver': 'liblinear'},\n",
       "  {'C': 1000000.0, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'saga'},\n",
       "  {'C': 10000000.0,\n",
       "   'multi_class': 'ovr',\n",
       "   'penalty': 'l1',\n",
       "   'solver': 'liblinear'},\n",
       "  {'C': 10000000.0, 'multi_class': 'ovr', 'penalty': 'l1', 'solver': 'saga'},\n",
       "  {'C': 10000000.0,\n",
       "   'multi_class': 'ovr',\n",
       "   'penalty': 'l2',\n",
       "   'solver': 'liblinear'},\n",
       "  {'C': 10000000.0, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'saga'},\n",
       "  {'C': 100000000.0,\n",
       "   'multi_class': 'ovr',\n",
       "   'penalty': 'l1',\n",
       "   'solver': 'liblinear'},\n",
       "  {'C': 100000000.0, 'multi_class': 'ovr', 'penalty': 'l1', 'solver': 'saga'},\n",
       "  {'C': 100000000.0,\n",
       "   'multi_class': 'ovr',\n",
       "   'penalty': 'l2',\n",
       "   'solver': 'liblinear'},\n",
       "  {'C': 100000000.0, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'saga'},\n",
       "  {'C': 1000000000.0,\n",
       "   'multi_class': 'ovr',\n",
       "   'penalty': 'l1',\n",
       "   'solver': 'liblinear'},\n",
       "  {'C': 1000000000.0, 'multi_class': 'ovr', 'penalty': 'l1', 'solver': 'saga'},\n",
       "  {'C': 1000000000.0,\n",
       "   'multi_class': 'ovr',\n",
       "   'penalty': 'l2',\n",
       "   'solver': 'liblinear'},\n",
       "  {'C': 1000000000.0,\n",
       "   'multi_class': 'ovr',\n",
       "   'penalty': 'l2',\n",
       "   'solver': 'saga'}],\n",
       " 'rank_test_Accuracy': array([71, 64, 26, 59, 71, 64, 26, 59, 71, 64, 26, 59, 71, 64, 26, 56, 71,\n",
       "        64, 24, 62, 71, 54, 21, 54, 26, 58, 23, 70, 24, 56, 31, 63, 41, 47,\n",
       "        22, 69, 20, 41, 19, 53,  7, 52, 17, 43, 15, 45, 15, 35,  7, 48, 17,\n",
       "        35,  7, 49,  7, 35,  5, 51,  4, 35,  7, 33,  5, 33,  7, 46,  1, 31,\n",
       "         7, 49,  1, 35,  7, 44,  1, 35], dtype=int32),\n",
       " 'rank_test_ErrorDistance': array([71, 61, 44, 66, 71, 61, 44, 66, 71, 61, 44, 68, 71, 61, 44, 69, 71,\n",
       "        61, 49, 60, 71, 57, 51, 56, 44, 54, 52, 70, 53, 55, 50, 59, 43, 36,\n",
       "        41, 58, 33, 24, 34, 42, 12, 40,  1, 31,  4, 30,  2, 20,  6, 35, 27,\n",
       "        18,  6, 38, 28, 18,  5, 39, 29, 21,  6, 17, 25, 15,  6, 32, 13,  3,\n",
       "         6, 37, 14, 21,  6, 26, 16, 21], dtype=int32),\n",
       " 'split0_test_Accuracy': array([ 0.00621118,  0.00621118,  0.42236025,  0.00621118,  0.00621118,\n",
       "         0.00621118,  0.42236025,  0.00621118,  0.00621118,  0.00621118,\n",
       "         0.42236025,  0.00621118,  0.00621118,  0.00621118,  0.42236025,\n",
       "         0.00621118,  0.00621118,  0.00621118,  0.42857143,  0.0931677 ,\n",
       "         0.00621118,  0.00621118,  0.49068323,  0.00621118,  0.42236025,\n",
       "         0.03726708,  0.45341615,  0.00621118,  0.42857143,  0.00621118,\n",
       "         0.45341615,  0.11801242,  0.40372671,  0.44720497,  0.48447205,\n",
       "         0.00621118,  0.45341615,  0.46583851,  0.47826087,  0.11180124,\n",
       "         0.48447205,  0.28571429,  0.46583851,  0.37888199,  0.47826087,\n",
       "         0.44099379,  0.48447205,  0.41614907,  0.48447205,  0.34782609,\n",
       "         0.47204969,  0.40993789,  0.48447205,  0.30434783,  0.47826087,\n",
       "         0.40993789,  0.48447205,  0.29192547,  0.47826087,  0.40993789,\n",
       "         0.48447205,  0.44720497,  0.47826087,  0.42857143,  0.48447205,\n",
       "         0.42857143,  0.47826087,  0.45341615,  0.48447205,  0.29813665,\n",
       "         0.47826087,  0.40993789,  0.48447205,  0.45962733,  0.47826087,\n",
       "         0.40993789]),\n",
       " 'split0_test_ErrorDistance': array([ 0.06667,  0.06667,  0.11111,  0.06667,  0.06667,  0.06667,\n",
       "         0.11111,  0.06667,  0.06667,  0.06667,  0.11111,  0.06667,\n",
       "         0.06667,  0.06667,  0.11111,  0.06667,  0.06667,  0.06667,\n",
       "         0.11136,  0.07231,  0.06667,  0.06667,  0.10695,  0.06707,\n",
       "         0.11111,  0.09091,  0.10331,  0.06667,  0.10299,  0.06671,\n",
       "         0.12005,  0.08052,  0.19881,  0.24272,  0.21186,  0.06671,\n",
       "         0.21598,  0.25316,  0.2381 ,  0.1199 ,  0.24213,  0.15106,\n",
       "         0.2381 ,  0.20161,  0.2451 ,  0.23419,  0.24331,  0.22727,\n",
       "         0.24814,  0.19048,  0.24272,  0.22727,  0.24814,  0.16077,\n",
       "         0.2451 ,  0.22727,  0.24814,  0.15748,  0.24331,  0.22676,\n",
       "         0.24814,  0.23529,  0.2451 ,  0.23256,  0.24814,  0.23095,\n",
       "         0.2451 ,  0.25126,  0.24814,  0.15974,  0.2451 ,  0.22676,\n",
       "         0.24814,  0.24938,  0.2451 ,  0.22676]),\n",
       " 'split0_train_Accuracy': array([ 0.00628931,  0.00628931,  0.42767296,  0.00628931,  0.00628931,\n",
       "         0.00628931,  0.42767296,  0.00628931,  0.00628931,  0.00628931,\n",
       "         0.42767296,  0.00628931,  0.00628931,  0.00628931,  0.42767296,\n",
       "         0.00628931,  0.00628931,  0.00628931,  0.43081761,  0.11320755,\n",
       "         0.00628931,  0.00628931,  0.44968553,  0.01257862,  0.42767296,\n",
       "         0.03144654,  0.43396226,  0.00628931,  0.44968553,  0.00628931,\n",
       "         0.44339623,  0.12264151,  0.37735849,  0.41194969,  0.47169811,\n",
       "         0.00628931,  0.46226415,  0.44654088,  0.49056604,  0.1572327 ,\n",
       "         0.51886792,  0.29245283,  0.5       ,  0.3836478 ,  0.49685535,\n",
       "         0.45283019,  0.49685535,  0.42138365,  0.50943396,  0.38050314,\n",
       "         0.49371069,  0.43081761,  0.50943396,  0.29559748,  0.49685535,\n",
       "         0.43081761,  0.50943396,  0.27044025,  0.49685535,  0.42767296,\n",
       "         0.50943396,  0.45283019,  0.50628931,  0.44968553,  0.50943396,\n",
       "         0.44025157,  0.51257862,  0.46540881,  0.50943396,  0.29874214,\n",
       "         0.51257862,  0.43081761,  0.50943396,  0.48113208,  0.51257862,\n",
       "         0.43081761]),\n",
       " 'split0_train_ErrorDistance': array([ 0.06667,  0.06667,  0.11111,  0.06667,  0.06667,  0.06667,\n",
       "         0.11111,  0.06667,  0.06667,  0.06667,  0.11111,  0.06667,\n",
       "         0.06667,  0.06667,  0.11111,  0.06667,  0.06667,  0.06667,\n",
       "         0.11123,  0.0613 ,  0.06667,  0.06667,  0.08315,  0.06954,\n",
       "         0.11111,  0.09091,  0.08899,  0.06667,  0.09132,  0.06676,\n",
       "         0.06289,  0.07553,  0.06711,  0.10836,  0.1211 ,  0.06545,\n",
       "         0.14403,  0.15021,  0.14316,  0.13072,  0.20408,  0.13021,\n",
       "         0.18157,  0.2193 ,  0.20349,  0.27701,  0.2    ,  0.25907,\n",
       "         0.20833,  0.21739,  0.20231,  0.15982,  0.20958,  0.12937,\n",
       "         0.20349,  0.15982,  0.20896,  0.12195,  0.20349,  0.15909,\n",
       "         0.20896,  0.17766,  0.25316,  0.16471,  0.20896,  0.2681 ,\n",
       "         0.38023,  0.13944,  0.20896,  0.13072,  0.38023,  0.15982,\n",
       "         0.20896,  0.23419,  0.38023,  0.15982]),\n",
       " 'split1_test_Accuracy': array([ 0.00625,  0.00625,  0.425  ,  0.00625,  0.00625,  0.00625,\n",
       "         0.425  ,  0.00625,  0.00625,  0.00625,  0.425  ,  0.00625,\n",
       "         0.00625,  0.00625,  0.425  ,  0.00625,  0.00625,  0.00625,\n",
       "         0.425  ,  0.0875 ,  0.00625,  0.125  ,  0.45625,  0.275  ,\n",
       "         0.425  ,  0.03125,  0.40625,  0.00625,  0.39375,  0.23125,\n",
       "         0.3625 ,  0.00625,  0.3625 ,  0.25   ,  0.3875 ,  0.01875,\n",
       "         0.4375 ,  0.2875 ,  0.45   ,  0.40625,  0.4375 ,  0.25625,\n",
       "         0.45625,  0.34375,  0.44375,  0.2625 ,  0.4375 ,  0.35625,\n",
       "         0.44375,  0.26875,  0.44375,  0.35625,  0.44375,  0.25625,\n",
       "         0.44375,  0.35625,  0.44375,  0.2625 ,  0.45   ,  0.35625,\n",
       "         0.44375,  0.35625,  0.45   ,  0.35625,  0.44375,  0.2625 ,\n",
       "         0.475  ,  0.35625,  0.44375,  0.2625 ,  0.475  ,  0.35625,\n",
       "         0.44375,  0.2625 ,  0.475  ,  0.35625]),\n",
       " 'split1_test_ErrorDistance': array([ 0.06667,  0.06667,  0.11111,  0.06667,  0.06667,  0.06667,\n",
       "         0.11111,  0.06667,  0.06667,  0.06667,  0.11111,  0.06667,\n",
       "         0.06667,  0.06667,  0.11111,  0.06667,  0.06667,  0.06667,\n",
       "         0.11111,  0.08873,  0.06667,  0.09091,  0.10917,  0.10449,\n",
       "         0.11111,  0.09091,  0.11198,  0.05924,  0.09823,  0.11521,\n",
       "         0.11641,  0.06671,  0.12438,  0.12626,  0.13643,  0.07072,\n",
       "         0.21231,  0.18282,  0.17513,  0.18149,  0.21142,  0.17857,\n",
       "         0.24096,  0.21008,  0.21231,  0.17953,  0.23474,  0.20921,\n",
       "         0.21142,  0.18018,  0.21053,  0.20921,  0.21142,  0.17794,\n",
       "         0.20619,  0.20921,  0.21142,  0.17953,  0.20704,  0.20921,\n",
       "         0.21142,  0.20619,  0.21598,  0.20921,  0.21142,  0.17953,\n",
       "         0.22883,  0.20921,  0.21142,  0.17953,  0.22779,  0.20921,\n",
       "         0.21142,  0.17953,  0.22727,  0.20921]),\n",
       " 'split1_train_Accuracy': array([ 0.00626959,  0.00626959,  0.42633229,  0.00626959,  0.00626959,\n",
       "         0.00626959,  0.42633229,  0.00626959,  0.00626959,  0.00626959,\n",
       "         0.42633229,  0.00626959,  0.00626959,  0.00626959,  0.42633229,\n",
       "         0.00626959,  0.00626959,  0.00626959,  0.42946708,  0.0846395 ,\n",
       "         0.00626959,  0.12539185,  0.46708464,  0.31347962,  0.42633229,\n",
       "         0.03448276,  0.46708464,  0.01567398,  0.45768025,  0.26959248,\n",
       "         0.42633229,  0.00626959,  0.40752351,  0.30407524,  0.50470219,\n",
       "         0.03448276,  0.55485893,  0.38244514,  0.55799373,  0.46708464,\n",
       "         0.56426332,  0.32601881,  0.57366771,  0.46081505,  0.5799373 ,\n",
       "         0.32601881,  0.57366771,  0.46081505,  0.5862069 ,  0.32601881,\n",
       "         0.5799373 ,  0.46394984,  0.59247649,  0.31974922,  0.5830721 ,\n",
       "         0.46394984,  0.59247649,  0.32601881,  0.5862069 ,  0.46394984,\n",
       "         0.59247649,  0.44200627,  0.58934169,  0.46394984,  0.59247649,\n",
       "         0.32601881,  0.59874608,  0.46394984,  0.59247649,  0.32601881,\n",
       "         0.59874608,  0.46394984,  0.59247649,  0.32601881,  0.59874608,\n",
       "         0.46394984]),\n",
       " 'split1_train_ErrorDistance': array([ 0.06667,  0.06667,  0.11111,  0.06667,  0.06667,  0.06667,\n",
       "         0.11111,  0.06667,  0.06667,  0.06667,  0.11111,  0.06667,\n",
       "         0.06667,  0.06667,  0.11111,  0.06662,  0.06667,  0.06667,\n",
       "         0.11123,  0.05882,  0.06667,  0.09091,  0.08485,  0.07181,\n",
       "         0.11111,  0.09091,  0.10757,  0.06993,  0.0795 ,  0.14556,\n",
       "         0.1113 ,  0.0668 ,  0.15129,  0.21834,  0.21097,  0.07825,\n",
       "         0.23753,  0.20284,  0.23923,  0.13563,  0.40816,  0.23641,\n",
       "         0.32051,  0.22371,  0.42918,  0.23095,  0.40486,  0.25907,\n",
       "         0.44643,  0.23202,  0.42373,  0.26042,  0.45045,  0.22936,\n",
       "         0.43103,  0.26042,  0.45045,  0.23148,  0.44643,  0.26042,\n",
       "         0.45045,  0.27701,  0.45045,  0.26042,  0.45045,  0.23095,\n",
       "         0.44444,  0.26042,  0.45045,  0.23148,  0.44444,  0.26042,\n",
       "         0.45045,  0.23148,  0.44444,  0.26042]),\n",
       " 'split2_test_Accuracy': array([ 0.00632911,  0.39873418,  0.43037975,  0.44936709,  0.00632911,\n",
       "         0.39873418,  0.43037975,  0.44936709,  0.00632911,  0.39873418,\n",
       "         0.43037975,  0.44936709,  0.00632911,  0.39873418,  0.43037975,\n",
       "         0.46202532,  0.00632911,  0.39873418,  0.43670886,  0.26582278,\n",
       "         0.00632911,  0.39873418,  0.43670886,  0.24683544,  0.43037975,\n",
       "         0.39873418,  0.4556962 ,  0.26582278,  0.46835443,  0.23417722,\n",
       "         0.37341772,  0.3164557 ,  0.35443038,  0.34810127,  0.4556962 ,\n",
       "         0.31012658,  0.50632911,  0.36708861,  0.49367089,  0.36075949,\n",
       "         0.51898734,  0.36708861,  0.50632911,  0.37974684,  0.51265823,\n",
       "         0.36075949,  0.51265823,  0.37341772,  0.51265823,  0.36075949,\n",
       "         0.51265823,  0.37974684,  0.51265823,  0.36075949,  0.51898734,\n",
       "         0.37974684,  0.51898734,  0.36075949,  0.52531646,  0.37974684,\n",
       "         0.51265823,  0.36075949,  0.51898734,  0.37974684,  0.51265823,\n",
       "         0.36075949,  0.51898734,  0.37974684,  0.51265823,  0.36075949,\n",
       "         0.51898734,  0.37974684,  0.51265823,  0.36075949,  0.51898734,\n",
       "         0.37974684]),\n",
       " 'split2_test_ErrorDistance': array([ 0.06667,  0.11111,  0.11111,  0.11074,  0.06667,  0.11111,\n",
       "         0.11111,  0.11074,  0.06667,  0.11111,  0.11111,  0.11062,\n",
       "         0.06667,  0.11111,  0.11111,  0.10917,  0.06667,  0.11111,\n",
       "         0.10953,  0.08562,  0.06667,  0.11111,  0.10571,  0.09823,\n",
       "         0.11111,  0.11111,  0.10604,  0.09653,  0.11001,  0.08953,\n",
       "         0.09242,  0.10604,  0.10183,  0.13228,  0.12755,  0.11682,\n",
       "         0.14045,  0.15748,  0.13966,  0.14556,  0.15267,  0.16103,\n",
       "         0.14948,  0.16207,  0.15314,  0.16077,  0.14903,  0.16103,\n",
       "         0.14903,  0.16129,  0.12953,  0.16129,  0.14903,  0.16077,\n",
       "         0.12987,  0.16129,  0.14925,  0.16077,  0.13021,  0.16129,\n",
       "         0.14903,  0.16077,  0.13004,  0.16129,  0.14903,  0.16077,\n",
       "         0.13004,  0.16129,  0.14903,  0.16077,  0.13004,  0.16129,\n",
       "         0.14903,  0.16077,  0.13004,  0.16129]),\n",
       " 'split2_train_Accuracy': array([ 0.00623053,  0.39875389,  0.42367601,  0.42367601,  0.00623053,\n",
       "         0.39875389,  0.42367601,  0.42367601,  0.00623053,  0.39875389,\n",
       "         0.42367601,  0.41433022,  0.00623053,  0.39875389,  0.42367601,\n",
       "         0.4423676 ,  0.00623053,  0.39875389,  0.43613707,  0.30841121,\n",
       "         0.00623053,  0.39875389,  0.46728972,  0.2741433 ,  0.42367601,\n",
       "         0.39875389,  0.40186916,  0.27725857,  0.42367601,  0.26168224,\n",
       "         0.3894081 ,  0.29595016,  0.38317757,  0.38317757,  0.42367601,\n",
       "         0.34579439,  0.5046729 ,  0.39875389,  0.48286604,  0.3894081 ,\n",
       "         0.53582555,  0.41433022,  0.54205607,  0.40809969,  0.56697819,\n",
       "         0.42056075,  0.5576324 ,  0.41744548,  0.56386293,  0.41433022,\n",
       "         0.56386293,  0.42056075,  0.56074766,  0.41744548,  0.55451713,\n",
       "         0.42056075,  0.56386293,  0.41744548,  0.55451713,  0.42056075,\n",
       "         0.56386293,  0.41744548,  0.55451713,  0.42056075,  0.56386293,\n",
       "         0.41744548,  0.55140187,  0.42056075,  0.56386293,  0.41744548,\n",
       "         0.55140187,  0.42056075,  0.56386293,  0.41744548,  0.55140187,\n",
       "         0.42056075]),\n",
       " 'split2_train_ErrorDistance': array([ 0.06667,  0.11111,  0.11111,  0.11074,  0.06667,  0.11111,\n",
       "         0.11111,  0.11074,  0.06667,  0.11111,  0.11111,  0.1105 ,\n",
       "         0.06667,  0.11111,  0.11111,  0.10787,  0.06667,  0.11111,\n",
       "         0.11173,  0.05332,  0.06667,  0.11111,  0.10893,  0.10953,\n",
       "         0.11111,  0.11111,  0.05607,  0.11223,  0.09785,  0.08985,\n",
       "         0.1218 ,  0.09833,  0.2045 ,  0.18868,  0.18315,  0.13141,\n",
       "         0.33333,  0.31153,  0.3012 ,  0.24272,  0.36101,  0.33333,\n",
       "         0.36496,  0.28571,  0.38023,  0.33333,  0.36765,  0.19789,\n",
       "         0.37879,  0.30864,  0.38023,  0.19947,  0.37879,  0.33223,\n",
       "         0.37594,  0.19947,  0.37879,  0.32895,  0.37313,  0.19947,\n",
       "         0.37879,  0.33223,  0.37037,  0.19947,  0.37879,  0.33223,\n",
       "         0.37037,  0.19947,  0.37879,  0.33113,  0.37037,  0.19947,\n",
       "         0.37879,  0.33223,  0.37037,  0.19947]),\n",
       " 'std_fit_time': array([  6.59289821e-04,   3.40019910e-04,   1.41510660e-04,\n",
       "          1.28000813e-03,   9.02270745e-05,   6.94673717e-05,\n",
       "          6.10032760e-05,   2.42926915e-04,   2.15276120e-05,\n",
       "          5.43553693e-05,   4.36235786e-05,   2.96774622e-04,\n",
       "          7.37267454e-05,   5.64689202e-05,   3.41165426e-05,\n",
       "          1.13967614e-03,   1.34130741e-04,   2.14465695e-04,\n",
       "          4.68403354e-05,   1.12528664e-03,   1.23645468e-04,\n",
       "          9.26532214e-05,   3.84957213e-05,   6.40784803e-01,\n",
       "          1.85752539e-04,   2.01521731e-03,   9.78311226e-05,\n",
       "          6.81944897e-01,   6.25609211e-04,   2.23345868e-02,\n",
       "          5.32897378e-05,   9.58612782e-02,   2.13108936e-03,\n",
       "          2.23838906e-01,   1.57294478e-04,   2.68304130e-01,\n",
       "          5.56438634e-02,   4.24800069e-01,   7.24666986e-05,\n",
       "          1.96638305e-01,   1.50198152e-01,   5.73517337e-01,\n",
       "          2.19339996e-04,   4.69329429e-01,   1.30066311e+00,\n",
       "          6.07707532e-01,   4.04455193e-04,   5.94610131e-01,\n",
       "          7.60084554e+00,   3.34164287e-01,   4.04615693e-04,\n",
       "          7.34647680e-01,   9.82071216e+00,   5.34934824e-01,\n",
       "          3.69443998e-04,   6.71212826e-01,   1.13191067e+01,\n",
       "          5.26846064e-01,   6.80940352e-04,   6.21636742e-01,\n",
       "          1.25727499e+01,   9.82676549e-01,   1.43980763e-03,\n",
       "          6.10124298e-01,   1.12552138e+01,   6.44918857e-01,\n",
       "          1.89422654e-03,   7.74073476e-01,   1.10653164e+01,\n",
       "          5.37895060e-01,   1.66789160e-03,   6.37133258e-01,\n",
       "          1.20753361e+01,   4.21176773e-01,   2.10195582e-03,\n",
       "          7.15087871e-01]),\n",
       " 'std_score_time': array([  6.25086176e-03,   4.82153397e-05,   1.62865118e-04,\n",
       "          4.28629190e-05,   2.28096799e-05,   1.34207990e-05,\n",
       "          2.56851070e-05,   2.94626804e-05,   2.57538666e-05,\n",
       "          1.20006650e-05,   1.74105429e-05,   1.05054584e-05,\n",
       "          7.16931535e-06,   4.05233662e-06,   4.35435852e-06,\n",
       "          5.08543097e-05,   3.12842568e-05,   7.29236136e-05,\n",
       "          2.90772938e-05,   5.17005007e-05,   6.46438318e-05,\n",
       "          7.03054128e-06,   5.41173413e-05,   8.06449449e-05,\n",
       "          3.59057290e-05,   2.31948400e-04,   2.80623698e-04,\n",
       "          2.40728002e-05,   3.37736279e-06,   3.88848935e-06,\n",
       "          2.90133632e-05,   5.86300755e-05,   8.00114501e-06,\n",
       "          3.55590758e-04,   1.02342963e-04,   8.50990691e-06,\n",
       "          1.27810594e-04,   6.10857372e-05,   4.97070814e-06,\n",
       "          3.02339660e-05,   3.97377014e-05,   5.12421870e-05,\n",
       "          7.47579018e-05,   2.94800393e-05,   1.23139343e-05,\n",
       "          3.05512941e-05,   2.36022352e-06,   6.61373692e-05,\n",
       "          1.08753026e-05,   1.24745001e-04,   1.72260059e-05,\n",
       "          9.00183718e-05,   6.74605219e-05,   1.06273965e-05,\n",
       "          6.09717934e-06,   8.82859416e-05,   9.89899470e-05,\n",
       "          6.60708697e-05,   5.73967936e-06,   1.30475946e-05,\n",
       "          1.08239409e-04,   4.59725593e-05,   4.02261439e-06,\n",
       "          1.50882275e-04,   2.85600735e-05,   7.68553917e-05,\n",
       "          3.60530097e-06,   7.67200051e-05,   4.34476023e-05,\n",
       "          4.90124016e-05,   7.50492305e-05,   3.20210876e-04,\n",
       "          1.31076937e-04,   5.92808938e-05,   1.48424624e-04,\n",
       "          7.12639829e-05]),\n",
       " 'std_test_Accuracy': array([  4.89982781e-05,   1.84539460e-01,   3.33188291e-03,\n",
       "          2.08345022e-01,   4.89982781e-05,   1.84539460e-01,\n",
       "          3.33188291e-03,   2.08345022e-01,   4.89982781e-05,\n",
       "          1.84539460e-01,   3.33188291e-03,   2.08345022e-01,\n",
       "          4.89982781e-05,   1.84539460e-01,   3.33188291e-03,\n",
       "          2.14296413e-01,   4.89982781e-05,   1.84539460e-01,\n",
       "          4.88662375e-03,   8.25363100e-02,   4.89982781e-05,\n",
       "          1.64080123e-01,   2.23198963e-02,   1.20905634e-01,\n",
       "          3.33188291e-03,   1.71375105e-01,   2.27975395e-02,\n",
       "          1.22049859e-01,   3.04113943e-02,   1.06997387e-01,\n",
       "          4.06286709e-02,   1.27948529e-01,   2.16200242e-02,\n",
       "          8.07189166e-02,   4.07430063e-02,   1.40044454e-01,\n",
       "          2.93398625e-02,   7.31427942e-02,   1.80590341e-02,\n",
       "          1.29745078e-01,   3.33379150e-02,   4.67462881e-02,\n",
       "          2.16429211e-02,   1.67757476e-02,   2.80726168e-02,\n",
       "          7.31746690e-02,   3.09545197e-02,   2.52535426e-02,\n",
       "          2.82389510e-02,   4.06614542e-02,   2.82120963e-02,\n",
       "          2.20341232e-02,   2.82389510e-02,   4.26142025e-02,\n",
       "          3.06807121e-02,   2.20341232e-02,   3.06912984e-02,\n",
       "          4.10647483e-02,   3.09865830e-02,   2.20341232e-02,\n",
       "          2.82389510e-02,   4.19471079e-02,   2.82478557e-02,\n",
       "          3.02052467e-02,   2.82389510e-02,   6.83379171e-02,\n",
       "          1.99568118e-02,   4.15034405e-02,   2.82389510e-02,\n",
       "          4.05112238e-02,   1.99568118e-02,   2.20341232e-02,\n",
       "          2.82389510e-02,   8.06867548e-02,   1.99568118e-02,\n",
       "          2.20341232e-02]),\n",
       " 'std_test_ErrorDistance': array([  0.00000000e+00,   2.08939041e-02,   1.38777878e-17,\n",
       "          2.07199449e-02,   0.00000000e+00,   2.08939041e-02,\n",
       "          1.38777878e-17,   2.07199449e-02,   0.00000000e+00,\n",
       "          2.08939041e-02,   1.38777878e-17,   2.06635257e-02,\n",
       "          0.00000000e+00,   2.08939041e-02,   1.38777878e-17,\n",
       "          1.99817940e-02,   0.00000000e+00,   2.08939041e-02,\n",
       "          8.08308863e-04,   7.13985216e-03,   0.00000000e+00,\n",
       "          1.81627315e-02,   1.42927931e-03,   1.64066068e-02,\n",
       "          1.38777878e-17,   9.49722913e-03,   3.62674836e-03,\n",
       "          1.60705539e-02,   4.82671139e-03,   1.98617601e-02,\n",
       "          1.22285925e-02,   1.62496566e-02,   4.14818021e-02,\n",
       "          5.36564664e-02,   3.78888527e-02,   2.26794471e-02,\n",
       "          3.46836635e-02,   4.05119187e-02,   4.07207649e-02,\n",
       "          2.53205021e-02,   3.70604841e-02,   1.13967519e-02,\n",
       "          4.23519821e-02,   2.08650803e-02,   3.80006603e-02,\n",
       "          3.11746310e-02,   4.24634450e-02,   2.79078762e-02,\n",
       "          4.08572142e-02,   1.20703806e-02,   4.75361970e-02,\n",
       "          2.77900197e-02,   4.08572142e-02,   8.09823014e-03,\n",
       "          4.77898967e-02,   2.77900197e-02,   4.07610497e-02,\n",
       "          9.72441208e-03,   4.70773418e-02,   2.76190797e-02,\n",
       "          4.08572142e-02,   3.06277310e-02,   4.87518645e-02,\n",
       "          2.96205438e-02,   4.08572142e-02,   2.96931971e-02,\n",
       "          5.07228248e-02,   3.67284136e-02,   4.08572142e-02,\n",
       "          9.10304380e-03,   5.05391408e-02,   2.76190797e-02,\n",
       "          4.08572142e-02,   3.81716642e-02,   5.04488364e-02,\n",
       "          2.76190797e-02]),\n",
       " 'std_train_Accuracy': array([  2.44257130e-05,   1.85014227e-01,   1.66094849e-03,\n",
       "          1.96762627e-01,   2.44257130e-05,   1.85014227e-01,\n",
       "          1.66094849e-03,   1.96762627e-01,   2.44257130e-05,\n",
       "          1.85014227e-01,   1.66094849e-03,   1.92356977e-01,\n",
       "          2.44257130e-05,   1.85014227e-01,   1.66094849e-03,\n",
       "          2.05573926e-01,   2.44257130e-05,   1.85014227e-01,\n",
       "          2.87922284e-03,   9.94397564e-02,   2.44257130e-05,\n",
       "          1.64296708e-01,   8.25077936e-03,   1.33543521e-01,\n",
       "          1.66094849e-03,   1.72439159e-01,   2.66252138e-02,\n",
       "          1.25582601e-01,   1.45170358e-02,   1.22300487e-01,\n",
       "          2.25321783e-02,   1.19020605e-01,   1.30661351e-02,\n",
       "          4.56093449e-02,   3.32676581e-02,   1.53830176e-01,\n",
       "          3.78460829e-02,   2.71985198e-02,   3.37473505e-02,\n",
       "          1.31633870e-01,   1.87290929e-02,   5.14022023e-02,\n",
       "          3.01753040e-02,   3.22000486e-02,   3.64962160e-02,\n",
       "          5.38110079e-02,   3.30842711e-02,   1.95824850e-02,\n",
       "          3.22418787e-02,   3.63802736e-02,   3.74384688e-02,\n",
       "          1.85159442e-02,   3.42148044e-02,   5.26780593e-02,\n",
       "          3.58602173e-02,   1.85159442e-02,   3.44436891e-02,\n",
       "          6.06065185e-02,   3.69877194e-02,   1.90006131e-02,\n",
       "          3.44436891e-02,   1.48041544e-02,   3.40528538e-02,\n",
       "          1.80565080e-02,   3.44436891e-02,   4.93604416e-02,\n",
       "          3.52350070e-02,   2.08062235e-02,   3.44436891e-02,\n",
       "          5.07645299e-02,   3.52350070e-02,   1.85159442e-02,\n",
       "          3.44436891e-02,   6.36613823e-02,   3.52350070e-02,\n",
       "          1.85159442e-02]),\n",
       " 'std_train_ErrorDistance': array([ 0.        ,  0.02094922,  0.        ,  0.0207748 ,  0.        ,\n",
       "         0.02094922,  0.        ,  0.0207748 ,  0.        ,  0.02094922,\n",
       "         0.        ,  0.02066166,  0.        ,  0.02094922,  0.        ,\n",
       "         0.01943366,  0.        ,  0.02094922,  0.0002357 ,  0.00333468,\n",
       "         0.        ,  0.01816753,  0.01177259,  0.01833985,  0.        ,\n",
       "         0.00952237,  0.02129474,  0.02075152,  0.00759441,  0.03307599,\n",
       "         0.0256562 ,  0.01329241,  0.05656225,  0.0464598 ,  0.0375659 ,\n",
       "         0.028559  ,  0.0772833 ,  0.06717107,  0.06501826,  0.0516789 ,\n",
       "         0.08724091,  0.08295224,  0.07811105,  0.03032003,  0.09693589,\n",
       "         0.04186636,  0.08910588,  0.02884053,  0.1001795 ,  0.04001559,\n",
       "         0.09578598,  0.0413755 ,  0.10098709,  0.08282003,  0.096924  ,\n",
       "         0.0413755 ,  0.10126687,  0.08455519,  0.10174612,  0.04165095,\n",
       "         0.10126687,  0.06395446,  0.08101737,  0.03955806,  0.10126687,\n",
       "         0.04183356,  0.03284054,  0.04939035,  0.10126687,  0.08181746,\n",
       "         0.03284054,  0.0413755 ,  0.10126687,  0.04686831,  0.03284054,\n",
       "         0.0413755 ])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchcv.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'mean_test_F1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-544bd47178ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msearchcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_test_F1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msearchcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_test_ErrorDistance'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msearchcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'mean_test_F1'"
     ]
    }
   ],
   "source": [
    "searchcv.cv_results_['mean_test_F1'][searchcv.cv_results_['mean_test_ErrorDistance'] == searchcv.best_score_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "searchcv.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_result = pd.concat([pd.Series(lr2_pred, name='Class'), pd.DataFrame(lr2_probas)], \n",
    "                      axis=1, names=[str(c) for c in range(lr2_probas.shape[1])])\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2.coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2.coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr1 = LogisticRegression(C=1e3, \n",
    "                         class_weight='balanced', \n",
    "                         random_state=129,\n",
    "                         multi_class='ovr',\n",
    "                         solver='liblinear')\n",
    "pipe1 = make_pipeline(StandardScaler(), lr2)\n",
    "\n",
    "pipe1.fit(X_train, y_train)\n",
    "\n",
    "print(pipe1)\n",
    "\n",
    "# make predictions\n",
    "lr1_pred = pipe1.predict(X_test)\n",
    "lr1_probas = pipe1.predict_proba(X_test)\n",
    "\n",
    "# summarize the fit of the model\n",
    "print(classification_report(y_test, lr1_pred))\n",
    "print(confusion_matrix(y_test, lr1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr2 = LogisticRegression(C=1e3, \n",
    "                         class_weight='balanced', \n",
    "                         random_state=129,\n",
    "                         multi_class='ovr',\n",
    "                         solver='liblinear')\n",
    "lr2.fit(X_train, y_train)\n",
    "# lr2.fit(X_train, y_train).decision_function(X_test, )\n",
    "\n",
    "print(lr2)\n",
    "\n",
    "# make predictions\n",
    "lr2_pred = lr2.predict(X_test)\n",
    "lr2_probas = lr2.predict_proba(X_test)\n",
    "\n",
    "# summarize the fit of the model\n",
    "print(classification_report(y_test, lr2_pred))\n",
    "print(confusion_matrix(y_test, lr2_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_rand_score(y_test, lr2_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "skplt.metrics.plot_confusion_matrix(y_test, lr2_pred, \n",
    "                                    normalize=True, cmap='RdYlGn', ax=ax)\n",
    "\n",
    "discrete_heatmap(confusion_matrix(y_test, lr2_pred))\n",
    "\n",
    "interpolated_heatmap(confusion_matrix(y_test, lr2_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "skplt.metrics.plot_roc_curve(y_test, lr2_probas, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "skplt.metrics.plot_precision_recall_curve(y_test, lr2_probas, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr3.coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr3 = LogisticRegression(C=1e3, \n",
    "                         class_weight='balanced', \n",
    "                         random_state=129,\n",
    "                         multi_class='multinomial',\n",
    "                         solver='newton-cg', max_iter=1000)\n",
    "lr3.fit(X_train, y_train)\n",
    "\n",
    "print(lr3)\n",
    "\n",
    "# make predictions\n",
    "lr3_pred = lr3.predict(X_test)\n",
    "lr3_probas = lr3.predict_log_proba(X_test)\n",
    "\n",
    "# summarize the fit of the model\n",
    "print(classification_report(y_test, lr3_pred))\n",
    "print(confusion_matrix(y_test, lr3_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "skplt.metrics.plot_confusion_matrix(y_test, lr3_pred, \n",
    "                                    normalize=True, cmap='RdYlGn', ax=ax)\n",
    "\n",
    "discrete_heatmap(confusion_matrix(y_test, lr3_pred))\n",
    "\n",
    "interpolated_heatmap(confusion_matrix(y_test, lr3_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "skplt.metrics.plot_roc_curve(y_test, lr3_probas, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "skplt.metrics.plot_precision_recall_curve(y_test, lr3_probas, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr4 = LogisticRegression(C=1e3, \n",
    "                         class_weight='balanced', \n",
    "                         random_state=129,\n",
    "                         multi_class='multinomial',\n",
    "                         solver='lbfgs')\n",
    "lr4.fit(X_train, y_train)\n",
    "\n",
    "print(lr4)\n",
    "\n",
    "# make predictions\n",
    "lr4_pred = lr4.predict(X_test)\n",
    "lr4_probas = lr4.predict_log_proba(X_test)\n",
    "\n",
    "# summarize the fit of the model\n",
    "print(classification_report(y_test, lr4_pred))\n",
    "print(confusion_matrix(y_test, lr4_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "skplt.metrics.plot_confusion_matrix(y_test, lr4_pred, \n",
    "                                    normalize=True, cmap='RdYlGn', ax=ax)\n",
    "\n",
    "discrete_heatmap(confusion_matrix(y_test, lr4_pred))\n",
    "\n",
    "interpolated_heatmap(confusion_matrix(y_test, lr4_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "skplt.metrics.plot_roc_curve(y_test, lr4_probas, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "skplt.metrics.plot_precision_recall_curve(y_test, lr4_probas, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr5 = LogisticRegression(C=1e3, \n",
    "                         class_weight='balanced', \n",
    "                         random_state=129,\n",
    "                         multi_class='multinomial',\n",
    "                         solver='sag',\n",
    "                         max_iter=10000*2.5)\n",
    "lr5.fit(X_train, y_train)\n",
    "\n",
    "print(lr5)\n",
    "\n",
    "# make predictions\n",
    "lr5_pred = lr5.predict(X_test)\n",
    "lr5_probas = lr5.predict_log_proba(X_test)\n",
    "\n",
    "# summarize the fit of the model\n",
    "print(classification_report(y_test, lr5_pred))\n",
    "print(confusion_matrix(y_test, lr5_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "skplt.metrics.plot_confusion_matrix(y_test, lr5_pred, \n",
    "                                    normalize=True, cmap='RdYlGn', ax=ax)\n",
    "\n",
    "discrete_heatmap(confusion_matrix(y_test, lr5_pred))\n",
    "\n",
    "interpolated_heatmap(confusion_matrix(y_test, lr5_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "skplt.metrics.plot_roc_curve(y_test, lr5_probas, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "skplt.metrics.plot_precision_recall_curve(y_test, lr5_probas, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr6 = LogisticRegression(C=1e3, \n",
    "                         class_weight='balanced', \n",
    "                         random_state=129,\n",
    "                         multi_class='multinomial',\n",
    "                         solver='saga',\n",
    "                         max_iter=10000*2.5)\n",
    "lr6.fit(X_train, y_train)\n",
    "\n",
    "print(lr6)\n",
    "\n",
    "# make predictions\n",
    "lr6_pred = lr6.predict(X_test)\n",
    "lr6_probas = lr6.predict_log_proba(X_test)\n",
    "\n",
    "# summarize the fit of the model\n",
    "print(classification_report(y_test, lr6_pred))\n",
    "print(confusion_matrix(y_test, lr6_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "skplt.metrics.plot_confusion_matrix(y_test, lr6_pred, \n",
    "                                    normalize=True, cmap='RdYlGn', ax=ax)\n",
    "\n",
    "discrete_heatmap(confusion_matrix(y_test, lr6_pred))\n",
    "\n",
    "interpolated_heatmap(confusion_matrix(y_test, lr6_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "skplt.metrics.plot_roc_curve(y_test, lr6_probas, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "skplt.metrics.plot_precision_recall_curve(y_test, lr6_probas, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Plot ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarize the output\n",
    "classes = sorted(y.unique())\n",
    "print(classes)\n",
    "# y2 = label_binarize(y, classes=classes)\n",
    "lb = LabelBinarizer()\n",
    "y2 = lb.fit_transform(y)\n",
    "n_classes = y2.shape[1]\n",
    "# Resplit using same seed\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y2, test_size=.7, random_state=129)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Learn to predict each class against the other\n",
    "classifier = OneVsRestClassifier(LogisticRegression(C=1000, class_weight='balanced', random_state=129))\n",
    "y_score = classifier.fit(X_train, y_train).decision_function(X_test)\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_probas = classifier.predict_proba(X_test)\n",
    "\n",
    "print(classifier)\n",
    "# print(classification_report(y_test, y_pred))\n",
    "print(classification_report(lb.inverse_transform(y_test), lb.inverse_transform(y_pred)))\n",
    "print(confusion_matrix(lb.inverse_transform(y_test), lb.inverse_transform(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "skplt.metrics.plot_confusion_matrix(lb.inverse_transform(y_test), \n",
    "                                    lb.inverse_transform(y_pred), \n",
    "                                    normalize=True, cmap='RdYlGn', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "skplt.metrics.plot_roc_curve(lb.inverse_transform(y_test), y_probas, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "skplt.metrics.plot_precision_recall_curve(lb.inverse_transform(y_test), y_probas, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_calibration_curve([lb.inverse_transform(y_test)], [y_probas])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
