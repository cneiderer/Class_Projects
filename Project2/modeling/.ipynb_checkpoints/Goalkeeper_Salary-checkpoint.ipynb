{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cneiderer/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import patsy\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import RidgeCV, LassoCV, ElasticNetCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import KFold\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.height', 1000)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "random.seed(129)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './clean_data/good_gk.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-0d17f71ec9cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./clean_data/good_gk.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './clean_data/good_gk.pkl'"
     ]
    }
   ],
   "source": [
    "df = pickle.load(open('./clean_data/good_gk.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df.head(5), df.tail(5)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10, random_state=129)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix Integer Column Dtypes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Set Integer Column Dtypes\n",
    "int_cols = ['GP', 'GS', 'MINS', 'G', 'A', 'SHTS_FP', 'SOG', 'GWG', \n",
    "            'HmG', 'RdG', 'Year', 'GWA', 'HmA', 'RdA', 'FC', 'FS', \n",
    "            'OFF', 'YC', 'RC', 'PKG_FP', 'PKA_FP', 'SHTS_GK', 'SV',\n",
    "            'GA', 'W', 'L', 'T', 'ShO', 'PKG_GK', 'PKA_GK']\n",
    "for col in int_cols:\n",
    "    df[col] = df[col].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename, Reorder, and Drop Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rename columns that have spaces in names\n",
    "df.rename(columns={'Base Salary': 'Salary', \n",
    "                   'Guaranteed Compensation': 'Total', \n",
    "                   'First Name': 'First',\n",
    "                   'Last Name': 'Last'}, inplace=True)\n",
    "df['Log_Salary'] = df['Salary'].map(np.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# idx = (df['GP'] == 0)\n",
    "# df['Wpct'][~idx] = (df['W'][~idx] + df['T'][~idx] * 0.5) / df[~idx][['W', 'L', 'T']].sum(axis=1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['Pts'] = df['W']*3 + df['L']*0 + df['T']*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df = df.drop(columns=['W', 'L', 'T', 'Wpct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df[df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Targeting Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = df[['Player', 'Club', 'POS', 'Salary', 'Log_Salary', 'Year', 'GP', 'GS', 'MINS', \n",
    "          'SHTS', 'SV', 'GA', 'GAA', 'ShO', 'SvPct', 'W', 'L', 'T']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df2 = df2[df2.Salary < 1e6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(num=None, figsize=(12, 8))\n",
    "ax = sns.distplot(df2['Salary'])\n",
    "ax.xaxis.set_label_text('Salary ($)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(num=None, figsize=(12, 8))\n",
    "ax = sns.distplot(df2['Log_Salary'])\n",
    "ax.xaxis.set_label_text('Log[Salary ($)]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corr2 = df2.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(num=None, figsize=(12, 8))\n",
    "sns.heatmap(corr2, center=0, cmap=sns.diverging_palette(10, 133, sep=80, n=20), vmin=-1, vmax=1, annot=True)\n",
    "# plt.title('Correlation Heatmap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(num=None)\n",
    "# sns.pairplot(df2.iloc[:, 3:])\n",
    "sns.pairplot(df2.iloc[:, 3:], diag_kind=\"kde\", kind='reg')\n",
    "plt.title('Pairplot Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Setup the data\n",
    "X = df2.iloc[:, 5:]\n",
    "X['Intercept'] = np.ones((len(X), 1))\n",
    "y = df2.iloc[:, 4]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=129)\n",
    "\n",
    "# Create your model\n",
    "model = sm.OLS(y_train, X_train, hasconst=True)\n",
    "# Fit your model to your training set\n",
    "fit = model.fit()\n",
    "# Print summary statistics of the model's performance\n",
    "fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.resid.plot(style='o', figsize=(15,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rsquared_adj(model, X, y):\n",
    "    return 1 - (1 - model.score(X, y)) * (len(y) - 1) / (len(y) - X.shape[1] - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_est = make_pipeline(PolynomialFeatures(1, interaction_only=True), RidgeCV(fit_intercept=True, normalize=True))\n",
    "r_est.fit(X_train, y_train)\n",
    "r_est.score(X_test, y_test)\n",
    "print('rsq:', r_est.score(X_test, y_test), \n",
    "      ', rsq_adj:', rsquared_adj(r_est, X_test, y_test))\n",
    "print('alpha:', r_est.steps[1][1].alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_est = make_pipeline(PolynomialFeatures(1, interaction_only=True), LassoCV(fit_intercept=True, normalize=True))\n",
    "l_est.fit(X_train, y_train)\n",
    "l_est.score(X_test, y_test)\n",
    "print('rsq:', l_est.score(X_test, y_test), \n",
    "      ', rsq_adj:', rsquared_adj(l_est, X_test, y_test))\n",
    "print('alpha:', l_est.steps[1][1].alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_est = make_pipeline(PolynomialFeatures(1, interaction_only=True), ElasticNetCV(l1_ratio=0.975, fit_intercept=True, normalize=True))\n",
    "e_est.fit(X_train, y_train)\n",
    "e_est.score(X_test, y_test)\n",
    "print('rsq:', e_est.score(X_test, y_test), \n",
    "      ', rsq_adj:', rsquared_adj(e_est, X_test, y_test))\n",
    "print('alpha:', e_est.steps[1][1].alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate Residuals\n",
    "yhat = pd.Series(e_est.predict(X), name='Predicted')\n",
    "residuals = yhat - y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot Fit\n",
    "sns.set_style('darkgrid')\n",
    "plt.figure(num=None, figsize=(15, 10))\n",
    "ax = sns.regplot(yhat, y,\n",
    "                 line_kws={'color':'red'}, \n",
    "                 scatter_kws={'alpha':1, 's':10});\n",
    "ax.set_xlabel('Predicted Salary [Log($)]')\n",
    "ax.set_ylabel('Actual Salary [Log($)]')\n",
    "ax.set_title('Predicted vs. Actual Salary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(num=None, figsize=(15, 10))\n",
    "ax = sns.jointplot(y, yhat, kind=\"reg\",\n",
    "                   line_kws={'color':'red'}, \n",
    "                   scatter_kws={'alpha':1, 's':10});\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(num=None, figsize=(15, 10))\n",
    "# ax = sns.jointplot(y, yhat, kind='resid',\n",
    "#                    line_kws={'color':'red'}, \n",
    "#                    scatter_kws={'alpha':1, 's':10});\n",
    "sns.jointplot(y, yhat, kind='kde')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(num=None, figsize=(15, 10))\n",
    "# ax = sns.jointplot(y, yhat, kind='resid',\n",
    "#                    line_kws={'color':'red'}, \n",
    "#                    scatter_kws={'alpha':1, 's':10});\n",
    "sns.regplot(y, yhat, kind='kde')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(num=None, figsize=(15, 10))\n",
    "ax = sns.jointplot(y, yhat, kind='resid',\n",
    "                   line_kws={'color':'red'}, \n",
    "                   scatter_kws={'alpha':1, 's':10});\n",
    "ax.set_axis_labels(ylabel='Residuals', xlabel='Actual Salary [Log($)]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot Residuals\n",
    "plt.figure(num=None, figsize=(15, 10))\n",
    "\n",
    "idx = np.random.permutation(np.arange(len(residuals)))\n",
    "idx = np.arange(len(residuals))\n",
    "ax = plt.scatter(idx, residuals)\n",
    "plt.title('Prediciton Residuals')\n",
    "\n",
    "# ax = sns.regplot(random_idx, residuals,\n",
    "#                  line_kws={'color':'red'}, \n",
    "#                  scatter_kws={'alpha':1, 's':10});\n",
    "# ax.set_ylabel('')\n",
    "# ax.set_title('Prediction Residuals')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log-Log Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3 = df[['Player', 'Club', 'POS', 'Salary', 'Log_Salary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df2.columns[5:]:\n",
    "    df3['Log_' + col] = df[col].map(lambda x: np.log(x+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3[df3.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corr3 = df3.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(num=None, figsize=(15, 10))\n",
    "sns.heatmap(corr3, center=0, cmap=sns.diverging_palette(10, 220, sep=80, n=20), vmin=-1, vmax=1)\n",
    "plt.title('Correlation Heatmap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(num=None)\n",
    "# sns.pairplot(df3.iloc[:, 3:])\n",
    "sns.pairplot(df3.iloc[:, 3:], diag_kind=\"kde\", kind='reg')\n",
    "plt.title('Pairplot Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Setup the data\n",
    "X = df3.iloc[:, 5:]\n",
    "# X['Intercept'] = np.ones((len(X), 1))\n",
    "y = df3.iloc[:, 4]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=129)\n",
    "\n",
    "# Create your model\n",
    "model = sm.OLS(y_train, X_train, hasconst=True)\n",
    "# Fit your model to your training set\n",
    "fit = model.fit()\n",
    "# Print summary statistics of the model's performance\n",
    "fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_est = make_pipeline(PolynomialFeatures(2, interaction_only=True), RidgeCV(fit_intercept=True, normalize=True))\n",
    "r_est.fit(X_train, y_train)\n",
    "r_est.score(X_test, y_test)\n",
    "print('rsq:', r_est.score(X_test, y_test), ', rsq_adj:', rsquared_adj(r_est, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l_est = make_pipeline(PolynomialFeatures(2, interaction_only=True), LassoCV(fit_intercept=True, normalize=True))\n",
    "l_est.fit(X_train, y_train)\n",
    "l_est.score(X_test, y_test)\n",
    "print('rsq:', l_est.score(X_test, y_test), ', rsq_adj:', rsquared_adj(l_est, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "e_est = make_pipeline(PolynomialFeatures(2, interaction_only=True), ElasticNetCV(l1_ratio=0.975, fit_intercept=True, normalize=True))\n",
    "e_est.fit(X_train, y_train)\n",
    "e_est.score(X_test, y_test)\n",
    "print('rsq:', e_est.score(X_test, y_test), ', rsq_adj:', rsquared_adj(e_est, X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combo Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df4 = df2.merge(df3, on=['Player', 'Club', 'POS', 'Salary', 'Log_Salary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Setup the data\n",
    "X = df4.iloc[:, 5:]\n",
    "# X['Intercept'] = np.ones((len(X), 1))\n",
    "y = df4.iloc[:, 4]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=129)\n",
    "\n",
    "# Create your model\n",
    "model = sm.OLS(y_train, X_train, hasconst=True)\n",
    "# Fit your model to your training set\n",
    "fit = model.fit()\n",
    "# Print summary statistics of the model's performance\n",
    "fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_est = make_pipeline(PolynomialFeatures(2, interaction_only=True), RidgeCV(fit_intercept=True, normalize=True))\n",
    "r_est.fit(X_train, y_train)\n",
    "r_est.score(X_test, y_test)\n",
    "print('rsq:', r_est.score(X_test, y_test), ', rsq_adj:', rsquared_adj(r_est, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l_est = make_pipeline(PolynomialFeatures(2, interaction_only=True), LassoCV(fit_intercept=True, normalize=True))\n",
    "l_est.fit(X_train, y_train)\n",
    "l_est.score(X_test, y_test)\n",
    "print('rsq:', l_est.score(X_test, y_test), ', rsq_adj:', rsquared_adj(l_est, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "e_est = make_pipeline(PolynomialFeatures(2, interaction_only=True), ElasticNetCV(l1_ratio=0.975, fit_intercept=True, normalize=True))\n",
    "e_est.fit(X_train, y_train)\n",
    "e_est.score(X_test, y_test)\n",
    "print('rsq:', e_est.score(X_test, y_test), ', rsq_adj:', rsquared_adj(e_est, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Setup the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, 5:], df.iloc[:, 0], test_size=0.3, random_state=129)\n",
    "\n",
    "# Create your model\n",
    "model = sm.OLS(y_train, X_train)\n",
    "# Fit your model to your training set\n",
    "fit = model.fit()\n",
    "# Print summary statistics of the model's performance\n",
    "fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Setup the data\n",
    "X = df.iloc[:, 5:]\n",
    "# X['Intercept'] = np.ones((len(X), 1))\n",
    "y = df.iloc[:, 4]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=129)\n",
    "\n",
    "# Create your model\n",
    "model = sm.OLS(y_train, X_train, hasconst=False)\n",
    "# Fit your model to your training set\n",
    "fit = model.fit()\n",
    "# Print summary statistics of the model's performance\n",
    "fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fit.resid.plot(style='o', figsize=(12,8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Setup the data\n",
    "X = df3.iloc[:, 5:]\n",
    "# X = df3.iloc[:, 19:]\n",
    "# X['Intercept'] = np.ones((len(X), 1))\n",
    "y = df3.iloc[:, 4]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=129)\n",
    "\n",
    "# Create your model\n",
    "model = sm.OLS(y_train, X_train, hasconst=False)\n",
    "# Fit your model to your training set\n",
    "fit = model.fit()\n",
    "# Print summary statistics of the model's performance\n",
    "fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fit.resid.plot(style='o', figsize=(12,8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "est = make_pipeline(PolynomialFeatures(2, interaction_only=True), LinearRegression())\n",
    "est.fit(X_train, y_train)\n",
    "est.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression(fit_intercept=False, normalize=False)\n",
    "lr.fit(X_train, y_train)\n",
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = RidgeCV(fit_intercept=False, normalize=False)\n",
    "lr.fit(X_train, y_train)\n",
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LassoCV(fit_intercept=False, normalize=False)\n",
    "lr.fit(X_train, y_train)\n",
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = ElasticNetCV(l1_ratio=0.025, fit_intercept=False, normalize=False)\n",
    "lr.fit(X_train, y_train)\n",
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Setup the data\n",
    "# # X = df3.iloc[:, 5:]\n",
    "# X = sm.add_constant(df[['GS', 'MINS', 'ShO']])\n",
    "# # y = df3.iloc[:, 0]\n",
    "# # y = df3['Salary']\n",
    "# y = df3['Log_Salary']\n",
    "\n",
    "# X = df3.iloc[:, 6]\n",
    "# X = sm.add_constant(df3.iloc[:, 6])\n",
    "\n",
    "df4 = df3[df3.GP > 0]\n",
    "X = sm.add_constant(df4.iloc[:, list(np.arange(8,16)) + [17,18]])\n",
    "y = df4['ShO'] #.map(lambda x: np.log(x+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(num=None, figsize=(15, 10))\n",
    "sns.heatmap(corr3, center=0, cmap=sns.diverging_palette(10, 220, sep=80, n=20), vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=129)\n",
    "\n",
    "# Create your model\n",
    "model = sm.OLS(y_train, X_train, hasconst=True)\n",
    "# Fit your model to your training set\n",
    "fit = model.fit()\n",
    "# Print summary statistics of the model's performance\n",
    "fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fit.resid.plot(style='o', figsize=(12,8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression(fit_intercept=True, normalize=True)\n",
    "lr.fit(X_train, y_train)\n",
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = RidgeCV(fit_intercept=True, normalize=True)\n",
    "lr.fit(X_train, y_train)\n",
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LassoCV(fit_intercept=False, normalize=False)\n",
    "lr.fit(X_train, y_train)\n",
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = ElasticNetCV(l1_ratio=0.95, fit_intercept=False, normalize=False)\n",
    "lr.fit(X_train, y_train)\n",
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "yhat = pd.Series(fit.predict(X_test), name='Pred_ShO')\n",
    "\n",
    "plt.figure(num=None, figsize=(15, 10))\n",
    "plt.scatter(yhat, y_test)\n",
    "plt.xlabel('yhat')\n",
    "plt.ylabel('ytest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.pairplot(X.join(y), diag_kind=\"kde\", kind='reg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = sns.PairGrid(X.join(y)) \n",
    "g.map_upper(sns.regplot) \n",
    "g.map_lower(sns.residplot) \n",
    "g.map_diag(sns.kdeplot, lw=3, legend=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(num=None, figsize=(15, 10))\n",
    "sns.regplot(yhat, y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corr3 = X.join(y).corr()\n",
    "corr3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.pairplot(X.join(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \n",
    "alphas = np.logspace(-9, 9, num=19)\n",
    "rscores = np.zeros(len(alphas))\n",
    "lscores = np.zeros(len(alphas))\n",
    "escores = np.zeros(len(alphas))\n",
    "for ii, a in enumerate(alphas):    \n",
    "    # RidgeCV\n",
    "    rcv = RidgeCV(cv=10, alphas=[a], fit_intercept=True)\n",
    "    rcv.fit(X, y)\n",
    "    rscores[ii] = rcv.score(X, y)\n",
    "    # LassoCV\n",
    "    lcv = LassoCV(cv=10, alphas=[a], fit_intercept=True)\n",
    "    lcv.fit(X, y)\n",
    "    lscores[ii] = lcv.score(X, y)    \n",
    "    # ElasticNetCV\n",
    "    ecv = ElasticNetCV(cv=10, alphas=[a], l1_ratio=0.5, fit_intercept=True)\n",
    "    ecv.fit(X, y)\n",
    "    escores[ii] = ecv.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.array([alphas, rscores, lscores, escores]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot the alpha vs. scores\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.semilogx(alphas, rscores, color='g', label='Ridge')\n",
    "plt.semilogx(alphas, lscores, color='b', label='Lasso')\n",
    "plt.semilogx(alphas, escores, color='r', label='ElasticNet')\n",
    "plt.ylim((0.0, 1e0))\n",
    "plt.ylabel('R^2')\n",
    "plt.xlabel('alpha')\n",
    "plt.title('Regularized Regression Comparsion')\n",
    "plt.legend(loc='lower left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = Ridge(alpha=100, fit_intercept=True, normalize=True)\n",
    "lr.fit(X_train, y_train)\n",
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coef = {}\n",
    "for idx, c in enumerate(X.columns):\n",
    "    coef[c] = lr.coef_[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = Lasso(alpha=0.01, fit_intercept=False, normalize=False)\n",
    "lr.fit(X_train, y_train)\n",
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = ElasticNet(alpha=0.01, l1_ratio=0.5, fit_intercept=False, normalize=False)\n",
    "lr.fit(X_train, y_train)\n",
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "454px",
    "left": "860.909px",
    "right": "20px",
    "top": "121px",
    "width": "344px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
